{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some text pre processing tasks\n",
    "#imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0% [                                                                            ]      0 / 127831\r",
      "  6% [....                                                                        ]   8192 / 127831\r",
      " 12% [.........                                                                   ]  16384 / 127831\r",
      " 19% [..............                                                              ]  24576 / 127831\r",
      " 25% [...................                                                         ]  32768 / 127831\r",
      " 32% [........................                                                    ]  40960 / 127831\r",
      " 38% [.............................                                               ]  49152 / 127831\r",
      " 44% [..................................                                          ]  57344 / 127831\r",
      " 51% [......................................                                      ]  65536 / 127831\r",
      " 57% [...........................................                                 ]  73728 / 127831\r",
      " 64% [................................................                            ]  81920 / 127831\r",
      " 70% [.....................................................                       ]  90112 / 127831\r",
      " 76% [..........................................................                  ]  98304 / 127831\r",
      " 83% [...............................................................             ] 106496 / 127831\r",
      " 89% [....................................................................        ] 114688 / 127831\r",
      " 96% [.........................................................................   ] 122880 / 127831\r",
      "100% [............................................................................] 127831 / 127831"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/combined_data (1).csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "url=\"https://drive.google.com/uc?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P\"\n",
    "path=\"../data\"\n",
    "wget.download(url,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good case Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>If you have several dozen or several hundred c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>If you are Razr owner...you must have this!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Needless to say I wasted my money.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>What a waste of money and time!.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  sentiment\n",
       "0           0  So there is no way for me to plug it in here i...          0\n",
       "1           1                         Good case Excellent value.          1\n",
       "2           2                             Great for the jawbone.          1\n",
       "3           3  Tied to charger for conversations lasting more...          0\n",
       "4           4                                  The mic is great.          1\n",
       "5           5  I have to jiggle the plug to get it to line up...          0\n",
       "6           6  If you have several dozen or several hundred c...          0\n",
       "7           7        If you are Razr owner...you must have this!          1\n",
       "8           8                 Needless to say I wasted my money.          0\n",
       "9           9                   What a waste of money and time!.          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the data\n",
    "\n",
    "def get_data(path):\n",
    "    data = pd.read_csv(path,header=0)\n",
    "    return data\n",
    "\n",
    "path=\"../data/combined_data.csv\"\n",
    "\n",
    "data = get_data(path)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>The whole experience was underwhelming and I t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>Then as if I hadn't wasted enough of my life t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1992 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sentiment\n",
       "0     So there is no way for me to plug it in here i...          0\n",
       "1                            Good case Excellent value.          1\n",
       "2                                Great for the jawbone.          1\n",
       "3     Tied to charger for conversations lasting more...          0\n",
       "4                                     The mic is great.          1\n",
       "...                                                 ...        ...\n",
       "1987  I think food should have flavor and texture an...          0\n",
       "1988                           Appetite instantly gone.          0\n",
       "1989  Overall I was not impressed and would not go b...          0\n",
       "1990  The whole experience was underwhelming and I t...          0\n",
       "1991  Then as if I hadn't wasted enough of my life t...          0\n",
       "\n",
       "[1992 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the unwanted column\n",
    "data.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'atalaia' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# clone package repository\n",
    "!git clone https://github.com/vallantin/atalaia.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n",
      "(null): can't open file 'setup.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# install packages requirements\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# install package\n",
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>no way plug us unless go converter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>good case excellent value</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>great jawbone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tied charger conversations lasting minutes maj...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mic great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  sentiment\n",
       "0           0                 no way plug us unless go converter          0\n",
       "1           1                          good case excellent value          1\n",
       "2           2                                      great jawbone          1\n",
       "3           3  tied charger conversations lasting minutes maj...          0\n",
       "4           4                                          mic great          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from atalaia.atalaia import Atalaia\n",
    "\n",
    "#preprocess function from atalaia module\n",
    "def preprocess(panda_series):\n",
    "    atalaia = Atalaia('en')\n",
    "\n",
    "    # lower case everyting and remove double spaces\n",
    "    panda_series = (atalaia.lower_remove_white(t) for t in panda_series)\n",
    "\n",
    "    # expand contractions\n",
    "    panda_series = (atalaia.expand_contractions(t) for t in panda_series)\n",
    "\n",
    "    # remove punctuation\n",
    "    panda_series = (atalaia.remove_punctuation(t) for t in panda_series)\n",
    "\n",
    "    # remove numbers\n",
    "    panda_series = (atalaia.remove_numbers(t) for t in panda_series)\n",
    "\n",
    "    # remove stopwords\n",
    "    panda_series = (atalaia.remove_stopwords(t) for t in panda_series)\n",
    "\n",
    "    # remove excessive spaces\n",
    "    panda_series = (atalaia.remove_excessive_spaces(t) for t in panda_series)\n",
    "\n",
    "    return panda_series\n",
    "\n",
    "# preprocess it\n",
    "preprocessed_text = preprocess(data.text)\n",
    "\n",
    "# assign preprocessed texts to dataset\n",
    "data['text'] = list(preprocessed_text)\n",
    "\n",
    "# see data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the dataset\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "# separate all classes present on the dataset\n",
    "classes_dict = {}\n",
    "for label in [0,1]:\n",
    "    classes_dict[label] = data[data['sentiment'] == label]\n",
    "\n",
    "# get 80% of each label\n",
    "size = int(len(classes_dict[0].text) * 0.8)\n",
    "X_train = list(classes_dict[0].text[0:size])      + list(classes_dict[1].text[0:size])\n",
    "X_test  = list(classes_dict[0].text[size:])       + list(classes_dict[1].text[size:])\n",
    "y_train = list(classes_dict[0].sentiment[0:size]) + list(classes_dict[1].sentiment[0:size])\n",
    "y_test  = list(classes_dict[0].sentiment[size:])  + list(classes_dict[1].sentiment[size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to Numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1058, 125, 58, 168, 2, 169]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's consider the vocab size as the number of words\n",
    "# that compose 90% of the vocabulary\n",
    "atalaia    = Atalaia('en')\n",
    "vocab_size = len(atalaia.representative_tokens(0.9, \n",
    "                                               ' '.join(X_train),\n",
    "                                               reverse=False))\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "# start tokenize\n",
    "tokenizer = Tokenizer(num_words=vocab_size, \n",
    "                      oov_token=oov_tok)\n",
    "\n",
    "# fit on training\n",
    "# we don't fit on test because, in real life, our model will have to deal with\n",
    "# words ir never saw before. So, it makes sense fitting only on training.\n",
    "# when it finds a word it never saw before, it will assign the \n",
    "# <OOV> tag to it.\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# get the word index\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# transform into sequences\n",
    "# this will assign a index to the tokens present on the corpus\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "# see the first sequence\n",
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1058,  125,   58,  168,    2,  169,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define max_length \n",
    "max_length = 100\n",
    "\n",
    "# post: pad or truncate after sentence.\n",
    "# pre: pad or truncate before sentence.\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "\n",
    "padded = pad_sequences(sequences,\n",
    "                       maxlen=max_length, \n",
    "                       padding=padding_type, \n",
    "                       truncating=trunc_type)\n",
    "\n",
    "# tokenize and pad test sentences\n",
    "# thse will be used later on the model for accuracy test\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_test_padded    = pad_sequences(X_test_sequences,\n",
    "                                 maxlen=max_length, \n",
    "                                 padding=padding_type, \n",
    "                                 truncating=trunc_type)\n",
    "\n",
    "# check the first padded sentence. Notice that 0s were added to it\n",
    "# because it was shorter than 100\n",
    "padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded sentence:\n",
      "say bye bye tip lady ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "\n",
      "Original sentence\n",
      "say bye bye tip lady\n"
     ]
    }
   ],
   "source": [
    "# create the reverse word index\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# create the decoder\n",
    "def text_decoder(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "# print the decoder output for one sentence and compare it to original\n",
    "print('Decoded sentence:')\n",
    "print(text_decoder(padded[1]))\n",
    "print('\\nOriginal sentence')\n",
    "print(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 16)           28512     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 9606      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 38,125\n",
      "Trainable params: 38,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build network\n",
    "embedding_dim = 16\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.6931 - accuracy: 0.5314 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6894 - accuracy: 0.6206 - val_loss: 0.6894 - val_accuracy: 0.5325\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.6510 - accuracy: 0.8109 - val_loss: 0.6671 - val_accuracy: 0.6350\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.5220 - accuracy: 0.9070 - val_loss: 0.6842 - val_accuracy: 0.6525\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.9108 - val_loss: 0.8384 - val_accuracy: 0.6400\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.2843 - accuracy: 0.9215 - val_loss: 0.7647 - val_accuracy: 0.6800\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2307 - accuracy: 0.9410 - val_loss: 0.8413 - val_accuracy: 0.6850\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1934 - accuracy: 0.9472 - val_loss: 0.7986 - val_accuracy: 0.7000\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1632 - accuracy: 0.9554 - val_loss: 0.8063 - val_accuracy: 0.7100\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.1411 - accuracy: 0.9611 - val_loss: 0.7710 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x204fb4e28d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "model.fit(padded, y_train, epochs=num_epochs, validation_data=(X_test_padded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 - 0s - loss: 0.7710 - accuracy: 0.7350\n",
      "\n",
      "Model accuracy: 74%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test_padded, y_test, verbose=2)\n",
    "print('\\nModel accuracy: {:.0f}%'.format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nothing smell better fragrance', 'everything perfect', 'respect environment', 'cake little dry', 'everything terrible', 'not work expected']\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict new reviews   \n",
    "new_reviews = ['Nothing could smell better than this fragrance.', 'Everything was perfect','They respect the environment.', 'The cake was a little dry','Everything was terrible.','it didn\\'t work as expected']\n",
    "\n",
    "# preprocess the texts\n",
    "new_reviews = list(preprocess(new_reviews))\n",
    "print(new_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sequences\n",
    "padding_type     = 'post'\n",
    "new_sequences    = tokenizer.texts_to_sequences(new_reviews)\n",
    "new_padded       = pad_sequences(new_sequences, padding=padding_type, maxlen=max_length)           \n",
    "\n",
    "# predict\n",
    "y_pred           = model.predict(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing smell better fragrance\n",
      "[0.88830435]\n",
      "\n",
      "\n",
      "everything perfect\n",
      "[0.32505876]\n",
      "\n",
      "\n",
      "respect environment\n",
      "[0.46855438]\n",
      "\n",
      "\n",
      "cake little dry\n",
      "[0.10603553]\n",
      "\n",
      "\n",
      "everything terrible\n",
      "[0.9970948]\n",
      "\n",
      "\n",
      "not work expected\n",
      "[0.04201415]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See the predictions\n",
    "for x in range(len(new_reviews)):\n",
    "  print(new_reviews[x])\n",
    "  print(y_pred[x])\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round\n",
    "y_pred = [1 if y > 0.5 else 0 for y in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "matrix = tf.math.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "matrix = np.array(matrix)\n",
    "\n",
    "matrix = pd.DataFrame(matrix, columns=['Positive (real)', 'Negative (real)'], index=['Positive (predicted)', 'Negative (predicted)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive (real)</th>\n",
       "      <th>Negative (real)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive (predicted)</th>\n",
       "      <td>107</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative (predicted)</th>\n",
       "      <td>13</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Positive (real)  Negative (real)\n",
       "Positive (predicted)              107               93\n",
       "Negative (predicted)               13              187"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "100Days",
   "language": "python",
   "name": "100days"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
